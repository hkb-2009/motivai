import os
import re
from typing import Optional

from flask import Flask, request, jsonify
from flask_cors import CORS
from dotenv import load_dotenv

# Gemini
import google.generativeai as genai

# ---------- Config & bootstrap ----------
load_dotenv()  # ƒë·ªçc .env n·∫øu c√≥

key = input("Enter Key: ")

GEMINI_API_KEY = os.getenv(key, "").strip()
MODEL_NAME = os.getenv("GEMINI_MODEL", "gemini-flash-latest")

app = Flask(__name__)
CORS(app, resources={r"/api/*": {"origins": "*"}})
# Block m·ªôt s·ªë n·ªôi dung nguy c∆° cao (b·∫°n c√≥ th·ªÉ m·ªü r·ªông)
BLOCKLIST = re.compile(
    r"(suicide|t·ª±\s*s√°t|ma\s*t√∫y|phishing|carding|hack\s*\*?ai)",
    re.IGNORECASE,
)

# N·∫øu c√≥ API key th√¨ kh·ªüi t·∫°o model
MODEL = None
if GEMINI_API_KEY:
    genai.configure(api_key=GEMINI_API_KEY)
    MODEL = genai.GenerativeModel(
        MODEL_NAME,
        generation_config={
            "temperature": 0.522,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 8192,
        },
        safety_settings=None,  # d√πng m·∫∑c ƒë·ªãnh c·ªßa Google; c√≥ th·ªÉ tu·ª≥ ch·ªânh theo ch√≠nh s√°ch
    )


# ---------- Helpers ----------
def stub_reply(msg: str) -> str:
    """Tr·∫£ l·ªùi t·∫°m khi ch∆∞a c√≥ API key (ƒë·ªÉ dev/test nhanh)."""
    trimmed = (msg or "").strip()
    if len(trimmed) > 100:
        trimmed = trimmed[:100] + "‚Ä¶"
    return (
        f"(MOTIVAI‚Äìstub) M√¨nh ƒë√£ nh·∫≠n m·ª•c ti√™u c·ªßa b·∫°n: ‚Äú{trimmed}‚Äù. "
        "B·∫Øt ƒë·∫ßu b·∫±ng 1 b∆∞·ªõc nh·ªè ngay h√¥m nay nh√©! üí™"
    )

'''
def motivate_users(msg: str) -> str:
    prompt = f"""
        B·∫°n l√† MOTIVAI ‚Äì tr·ª£ l√Ω AI h·ªó tr·ª£ thay ƒë·ªïi h√†nh vi v√† x√¢y d·ª±ng th√≥i quen l√†nh m·∫°nh
        
        NGUY√äN T·∫ÆC HO·∫†T ƒê·ªòNG:
        1) N·∫øu ƒë√¢y l√† l·∫ßn ƒë·∫ßu ng∆∞·ªùi d√πng nh·∫Øc t·ªõi m·ªôt v·∫•n ƒë·ªÅ m·ªõi 
           (v√≠ d·ª•: cai nghi·ªán, h·ªçc t·∫≠p, s·ª©c kh·ªèe, c·∫£m x√∫c...) 
           v√† th√¥ng tin c√≤n chung chung, 
           H√ÉY:
           
        CH·ªà ƒë·∫∑t 2‚Äì3 c√¢u h·ªèi l√†m r√µ (ng·∫Øn, d·ªÖ tr·∫£ l·ªùi).
        Kh√¥ng t∆∞ v·∫•n s√¢u, ch·ªâ n√≥i 1 c√¢u ng·∫Øn ki·ªÉu ‚Äúƒê·ªÉ gi√∫p b·∫°n t·ªët h∆°n m√¨nh h·ªèi nhanh v√†i √Ω‚Ä¶‚Äù
        
        2) N·∫øu ng∆∞·ªùi d√πng ƒë√£ cung c·∫•p kh√° nhi·ªÅu th√¥ng tin v·ªÅ c√πng m·ªôt v·∫•n ƒë·ªÅ 
           (ƒë√£ tr·∫£ l·ªùi c√°c c√¢u h·ªèi tr∆∞·ªõc ƒë√≥):
           
        B·∫Øt ƒë·∫ßu b·∫±ng 1‚Äì2 c√¢u t√≥m t·∫Øt l·∫°i b·ªëi c·∫£nh c·ªßa h·ªç
        Sau ƒë√≥ ƒë∆∞a ra g·ª£i √Ω / k·∫ø ho·∫°ch h√†nh ƒë·ªông c·ª• th·ªÉ theo t·ª´ng b∆∞·ªõc.
        K·∫øt th√∫c b·∫±ng 1 c√¢u ƒë·ªông vi√™n r√µ r√†ng, d·ªÖ th·ª±c hi·ªán ngay h√¥m nay
        
        3) Lu√¥n d√πng gi·ªçng vƒÉn:
           
        T√¥n tr·ªçng, kh√¥ng ph√°n x√©t.
        T√≠ch c·ª±c, th·ª±c t·∫ø, kh√¥ng ‚Äúch·ªØa l√†nh‚Äù s√°o r·ªóng.
        C√¢u ng·∫Øn, d·ªÖ ƒë·ªçc tr√™n m√†n h√¨nh ƒëi·ªán tho·∫°i.
        
        Tin nh·∫Øn ng∆∞·ªùi d√πng:
        "{message}"
        
        H√£y tr·∫£ l·ªùi ƒë√∫ng theo NGUY√äN T·∫ÆC HO·∫†T ƒê·ªòNG ·ªü tr√™n.
        """
    response = model.generate_content(prompt)
    return response.text.strip()
''' ## APPARENTLY THIS FUNCTION IS NEVER USED ##

def build_system_prompt(category: Optional[str]) -> str:
    """
    Prompt h·ªá th·ªëng nh·∫π, ƒëi·ªÅu ch·ªânh gi·ªçng ƒëi·ªáu theo nh√≥m.
    category ‚àà {'habit','study','emotion'} n·∫øu frontend g·ª≠i.
    """
    base = (
        """
            B·∫°n l√† MOTIVAI ‚Äì tr·ª£ l√Ω AI h·ªó tr·ª£ thay ƒë·ªïi h√†nh vi v√† x√¢y d·ª±ng th√≥i quen l√†nh m·∫°nh

            NGUY√äN T·∫ÆC HO·∫†T ƒê·ªòNG:
            1) N·∫øu ƒë√¢y l√† l·∫ßn ƒë·∫ßu ng∆∞·ªùi d√πng nh·∫Øc t·ªõi m·ªôt v·∫•n ƒë·ªÅ m·ªõi 
               (v√≠ d·ª•: cai nghi·ªán, h·ªçc t·∫≠p, s·ª©c kh·ªèe, c·∫£m x√∫c...) 
               v√† th√¥ng tin c√≤n chung chung, 
               H√ÉY:

            CH·ªà ƒë·∫∑t 2‚Äì3 c√¢u h·ªèi l√†m r√µ (ng·∫Øn, d·ªÖ tr·∫£ l·ªùi).
            Kh√¥ng t∆∞ v·∫•n s√¢u, ch·ªâ n√≥i 1 c√¢u ng·∫Øn ki·ªÉu ‚Äúƒê·ªÉ gi√∫p b·∫°n t·ªët h∆°n m√¨nh h·ªèi nhanh v√†i √Ω‚Ä¶‚Äù

            2) N·∫øu ng∆∞·ªùi d√πng ƒë√£ cung c·∫•p kh√° nhi·ªÅu th√¥ng tin v·ªÅ c√πng m·ªôt v·∫•n ƒë·ªÅ 
               (ƒë√£ tr·∫£ l·ªùi c√°c c√¢u h·ªèi tr∆∞·ªõc ƒë√≥):

            B·∫Øt ƒë·∫ßu b·∫±ng 1‚Äì2 c√¢u t√≥m t·∫Øt l·∫°i b·ªëi c·∫£nh c·ªßa h·ªç
            Sau ƒë√≥ ƒë∆∞a ra g·ª£i √Ω / k·∫ø ho·∫°ch h√†nh ƒë·ªông c·ª• th·ªÉ theo t·ª´ng b∆∞·ªõc.
            K·∫øt th√∫c b·∫±ng 1 c√¢u ƒë·ªông vi√™n r√µ r√†ng, d·ªÖ th·ª±c hi·ªán ngay h√¥m nay

            3) Lu√¥n d√πng gi·ªçng vƒÉn:

            T√¥n tr·ªçng, kh√¥ng ph√°n x√©t.
            T√≠ch c·ª±c, th·ª±c t·∫ø, kh√¥ng ‚Äúch·ªØa l√†nh‚Äù s√°o r·ªóng.
            C√¢u ng·∫Øn, d·ªÖ ƒë·ªçc tr√™n m√†n h√¨nh ƒëi·ªán tho·∫°i.

            Tin nh·∫Øn ng∆∞·ªùi d√πng:
            "{message}"

            H√£y tr·∫£ l·ªùi ƒë√∫ng theo NGUY√äN T·∫ÆC HO·∫†T ƒê·ªòNG ·ªü tr√™n.
        """
        "You are MOTIVAI, a concise, upbeat motivation coach. "
        "Always be practical, non-judgmental, and action-oriented. "
        "Give a solution, a roadmap to help with the problem. "
        "Write 2‚Äì5 short bullet points max, in Vietnamese, with 1 emoji at the end.\n"
        "Reponse in relation with the question. "
    )
    if category == "habit":
        base += "Focus on tiny habits, triggers, and 1 next action in under 30 seconds.\n"
    elif category == "study":
        base += "Focus on time-blocks, distraction control, and a 25‚Äì50 minute plan.\n"
    elif category == "emotion":
        base += "Acknowledge feelings, suggest one grounding technique, and a small step.\n"
    return base


def call_gemini(user_message: str, category: Optional[str], history: list[dict]) -> str:
    """G·ªçi Gemini v·ªõi l·ªãch s·ª≠ chat v√† system instruction ch√≠nh x√°c."""
    sys_instruction = build_system_prompt(category)
    current_model = genai.GenerativeModel(
        MODEL_NAME,
        system_instruction=sys_instruction,
        generation_config={
            "temperature": 0.522,
            "top_p": 0.95,
            "top_k": 40,
            "max_output_tokens": 8192,
        }
    )

    gemini_history = []
    for turn in history:
        if turn.get("role") in ["user", "model"] and turn.get("parts"):
            gemini_history.append({
                "role": turn["role"],
                "parts": turn["parts"]
            })

    chat_session = current_model.start_chat(history=gemini_history)

    try:
        resp = chat_session.send_message(user_message)

        text = getattr(resp, "text", "") or ""
        text = text.replace("[LINEBREAK]", "\n\n")
        return text.strip()
    except Exception as e:
        print("Error Message inside call_gemini:", e)
        return ""


# ---------- Routes ----------
@app.get("/health")
def health():
    return jsonify(
        {
            "ok": True,
            "service": "motivai-backend",
            "model": MODEL_NAME,
            "gemini_configured": bool(MODEL),
        }
    )


@app.post("/api/chat")
def chat():
    data = request.get_json(silent=True) or {}
    message = (data.get("message") or "").strip()
    category = (data.get("category") or "").strip().lower() or None

    history = data.get("history") or []

    # Validate
    if not message or len(message) > 2000:
        return jsonify(error="message invalid or too long"), 400
    if BLOCKLIST.search(message):
        return jsonify(error="topic not supported"), 400

    # N·∫øu ch∆∞a c·∫•u h√¨nh API key -> stub
    if not GEMINI_API_KEY:
        return jsonify(reply=stub_reply(message), mode="stub"), 200

    try:
        reply = call_gemini(message, category, history)
        if not reply:
            return jsonify(reply="M√¨nh ƒëang g·∫∑p ch√∫t s·ª± c·ªë, th·ª≠ l·∫°i gi√∫p m√¨nh nh√©!", mode="error"), 200
        return jsonify(reply=reply, mode="gemini"), 200
    except Exception as e:
        print("Error Message:", e)
        # fallback an to√†n
        return jsonify(reply=stub_reply(message), mode="fallback", detail=str(e)), 200

# ---------- Entrypoint ----------
if __name__ == "__main__":
    # Ch·∫°y local: python backend/app.py
    port = int(os.getenv("PORT", "8000"))
    app.run(host="0.0.0.0", port=port, debug=os.getenv("DEBUG", "false") == "true")